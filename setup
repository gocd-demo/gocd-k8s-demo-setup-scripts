#!/bin/bash
# Paste the entire script below at https://argbash.io/generate to create the command line parser
# ARG_OPTIONAL_SINGLE([project-name],[p],[the GCP project name to use for this invocation])
# ARG_OPTIONAL_SINGLE([cluster-name-prefix],[c],[the prefix to be used to generate the name of the cluster])
# ARG_OPTIONAL_SINGLE([number-of-clusters],[n],[the number of the clusters to create],[1])
# ARG_OPTIONAL_SINGLE([machine-type],[t],[the type of machine],[g1-small])
# ARG_OPTIONAL_SINGLE([disk-size],[d],[the size of the disk (in GB)],[50])
# ARGBASH_GO()
# needed because of Argbash --> m4_ignore([
### START OF CODE GENERATED BY Argbash v2.6.1 one line above ###
# Argbash is a bash code generator used to get arguments parsing right.
# Argbash is FREE SOFTWARE, see https://argbash.io for more info
# Generated online by https://argbash.io/generate

die()
{
  local _ret=$2
  test -n "$_ret" || _ret=1
  test "$_PRINT_HELP" = yes && print_help >&2
  echo "$1" >&2
  exit ${_ret}
}

begins_with_short_option()
{
  local first_option all_short_options
  all_short_options='pcntdk'
  first_option="${1:0:1}"
  test "$all_short_options" = "${all_short_options/$first_option/}" && return 1 || return 0
}



# THE DEFAULTS INITIALIZATION - OPTIONALS
_arg_project_name=
_arg_cluster_name_prefix=
_arg_number_of_clusters="1"
_arg_machine_type="g1-small"
_arg_disk_size="50"

print_help ()
{
  printf 'Usage: %s [-p|--project-name <arg>] [-c|--cluster-name-prefix <arg>] [-n|--number-of-clusters <arg>] [-t|--machine-type <arg>] [-d|--disk-size <arg>] [-k|--ssh-private-key <arg>]\n' "$0"
  printf '\t%s\n' "-p,--project-name: the GCP project name to use for this invocation (no default)"
  printf '\t%s\n' "-c,--cluster-name-prefix: the prefix to be used to generate the name of the cluster (no default)"
  printf '\t%s\n' "-n,--number-of-clusters: the number of the clusters to create (default: '1')"
  printf '\t%s\n' "-t,--machine-type: the type of machine (default: 'g1-small')"
  printf '\t%s\n' "-d,--disk-size: the size of the disk (in GB) (default: '50')"
}

parse_commandline ()
{
  while test $# -gt 0
  do
    _key="$1"
    case "$_key" in
      -p|--project-name)
        test $# -lt 2 && die "Missing value for the optional argument '$_key'." 1
        _arg_project_name="$2"
        shift
        ;;
      --project-name=*)
        _arg_project_name="${_key##--project-name=}"
        ;;
      -p*)
        _arg_project_name="${_key##-p}"
        ;;
      -c|--cluster-name-prefix)
        test $# -lt 2 && die "Missing value for the optional argument '$_key'." 1
        _arg_cluster_name_prefix="$2"
        shift
        ;;
      --cluster-name-prefix=*)
        _arg_cluster_name_prefix="${_key##--cluster-name-prefix=}"
        ;;
      -c*)
        _arg_cluster_name_prefix="${_key##-c}"
        ;;
      -n|--number-of-clusters)
        test $# -lt 2 && die "Missing value for the optional argument '$_key'." 1
        _arg_number_of_clusters="$2"
        shift
        ;;
      --number-of-clusters=*)
        _arg_number_of_clusters="${_key##--number-of-clusters=}"
        ;;
      -n*)
        _arg_number_of_clusters="${_key##-n}"
        ;;
      -t|--machine-type)
        test $# -lt 2 && die "Missing value for the optional argument '$_key'." 1
        _arg_machine_type="$2"
        shift
        ;;
      --machine-type=*)
        _arg_machine_type="${_key##--machine-type=}"
        ;;
      -t*)
        _arg_machine_type="${_key##-t}"
        ;;
      -d|--disk-size)
        test $# -lt 2 && die "Missing value for the optional argument '$_key'." 1
        _arg_disk_size="$2"
        shift
        ;;
      --disk-size=*)
        _arg_disk_size="${_key##--disk-size=}"
        ;;
      -d*)
        _arg_disk_size="${_key##-d}"
        ;;
      *)
        _PRINT_HELP=yes die "FATAL ERROR: Got an unexpected argument '$1'" 1
        ;;
    esac
    shift
  done
}

parse_commandline "$@"

# OTHER STUFF GENERATED BY Argbash

### END OF CODE GENERATED BY Argbash (sortof) ### ])
# [ <-- needed because of Argbash

function info() {
  printf "\033[1;34m[INFO]\033[0m ${1}\n"
}

function warn() {
  printf "\033[1;33m[WARN]\033[0m ${1}\n"
}

function error() {
  printf "\033[1;31m[ERROR]\033[0m ${1}\n"
}

if [ -z "${_arg_project_name}" ] || [ -z "${_arg_cluster_name_prefix}" ]; then
  print_help
  die "Missing required parameters" 1
fi

CONFIG_DIR="${HOME}/.gocd-demo/${_arg_cluster_name_prefix}"
mkdir -p "${CONFIG_DIR}"
SSH_PRIVATE_KEY="${CONFIG_DIR}/id_ed25519"
SSH_CONSOLE_INSTANCE_NAME="${_arg_cluster_name_prefix}-ssh-console"
SSH_USER="cloud-user"

info "Creating a new ssh key pair..."
ssh-keygen -t ed25519 -N "" -f "${SSH_PRIVATE_KEY}"

info "Spinning up a new VM instance...."
gcloud compute \
  --project "${_arg_project_name}" instances create "${SSH_CONSOLE_INSTANCE_NAME}" \
  --async \
  --description "Instance for workshop attendees to be able to use k8s" \
  --zone us-central1-a \
  --machine-type n1-standard-1 \
  --subnet default \
  --network-tier PREMIUM \
  --metadata ssh-keys="${SSH_USER}:$(cat "${SSH_PRIVATE_KEY}.pub")" \
  --no-restart-on-failure \
  --maintenance-policy MIGRATE \
  --image ubuntu-1804-bionic-v20190514 \
  --image-project ubuntu-os-cloud \
  --boot-disk-size 10GB \
  --boot-disk-type pd-standard \
  --boot-disk-device-name "${SSH_CONSOLE_INSTANCE_NAME}" \
  &

info "Spinning up ${_arg_number_of_clusters} clusters. This will take a few minutes..."
for cluster_index in $(seq 1 "${_arg_number_of_clusters}")
do
  cluster_name="${_arg_cluster_name_prefix}-user-${cluster_index}"
  gcloud beta container \
      --project "${_arg_project_name}" clusters create "${cluster_name}" \
      --zone "us-central1-a" \
      --no-enable-basic-auth \
      --cluster-version "1.13.7-gke.8" \
      --machine-type "${_arg_machine_type}" \
      --image-type "COS" \
      --disk-type "pd-standard" \
      --disk-size "${_arg_disk_size}" \
      --num-nodes "1" \
      --no-enable-cloud-logging \
      --no-enable-cloud-monitoring \
      --no-enable-ip-alias \
      --network "projects/${_arg_project_name}/global/networks/default" \
      --subnetwork "projects/${_arg_project_name}/regions/us-central1/subnetworks/default" \
      --addons HorizontalPodAutoscaling,HttpLoadBalancing \
      --enable-autoupgrade \
      --enable-autorepair \
      --enable-autoscaling \
      --max-nodes=3 \
      --min-nodes=1 \
      &
done

wait

SSH_IP_ADDRESS="$(
  gcloud compute \
  --project "${_arg_project_name}" instances list \
  --filter="name:${SSH_CONSOLE_INSTANCE_NAME}" \
  --format 'get(networkInterfaces[0].accessConfigs[0].natIP)'
)"

SSH_OPTIONS="-i ${SSH_PRIVATE_KEY} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
SSH_COMMAND="ssh ${SSH_OPTIONS} ${SSH_USER}@${SSH_IP_ADDRESS}"

info "Installing kubectl..."
${SSH_COMMAND} -tt 'sudo snap install kubectl --classic'

info "Installing helm..."
${SSH_COMMAND} -tt 'sudo snap install helm --classic'

info "Enabling password authentication for SSH."
${SSH_COMMAND} -tt "sudo sed -e 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config -i; sudo service sshd reload"

info "Creating ${_arg_number_of_clusters} users on ssh host with access to k8s cluster."
for cluster_index in $(seq 1 "${_arg_number_of_clusters}")
do
  # export the kube config file to local file
  cluster_name="${_arg_cluster_name_prefix}-user-${cluster_index}"
  KUBECONFIG_DIR="${CONFIG_DIR}/${cluster_name}/kube"
  KUBECONFIG="${KUBECONFIG_DIR}/config"
  mkdir -p "$(dirname "${KUBECONFIG}")"

  # generate a temporary kube config
  KUBECONFIG=${KUBECONFIG} gcloud container clusters get-credentials "${cluster_name}"
  sed -e 's/cmd-path: .*/cmd-path: gcloud/g' "${KUBECONFIG}" -i

  # execute a dummy command
  kubectl --kubeconfig="${KUBECONFIG}" get nodes

  info "Creating user 'admin-user'"
  kubectl --kubeconfig="${KUBECONFIG}" apply -f "dashboard-adminuser.yaml"

  info "Getting token for 'admin-user'"
  kubectl --kubeconfig="${KUBECONFIG}" -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}') > "${KUBECONFIG_DIR}/token"

  info "Applying ClusterRoleBinding for 'admin-user'"
  kubectl --kubeconfig="${KUBECONFIG}" apply -f "admin-user-cluster-role-binding.yaml"

  # generate a more permanent kube config using a template
  CLUSTER_USER_TOKEN=$(kubectl --kubeconfig="${KUBECONFIG}" describe secrets --namespace=kube-system admin-user | grep '^token: ' | awk '{print $2}')
  CLUSTER_DESCRIPTION="$(gcloud container clusters describe "${cluster_name}")"
  CLUSTER_URL="$(echo "${CLUSTER_DESCRIPTION}" | grep -E '^endpoint:' | awk '{print $2}')"
  CLUSTER_NAME="$(echo "${CLUSTER_DESCRIPTION}" | grep -E '^name:' | awk '{print $2}')"
  CLUSTER_CA_CERT="$(echo "${CLUSTER_DESCRIPTION}" | grep -E '^  clusterCaCertificate:' | awk '{print $2}')"

  cat "kube-config.template.yaml" | sed \
                                          -e "s/@@CLUSTER_URL@@/$CLUSTER_URL/g" \
                                          -e "s/@@CLUSTER_NAME@@/$CLUSTER_NAME/g" \
                                          -e "s/@@CLUSTER_CA_CERT@@/$CLUSTER_CA_CERT/g" \
                                          -e "s/@@CLUSTER_USER_TOKEN@@/$CLUSTER_USER_TOKEN/g" > "${KUBECONFIG}"

  # copy over the kube config to remote host
  info "Copying over kube config to remote host"
  rsync --quiet -azP -e "ssh ${SSH_OPTIONS}" "${KUBECONFIG_DIR}/" "${SSH_USER}@${SSH_IP_ADDRESS}:.kube"
  REMOTE_PORT="$((3023 * $cluster_index))"
  cat bash_login | sed -e "s/@@REMOTE_PORT@@/$REMOTE_PORT/g" -e "s/@@SSH_IP_ADDRESS@@/$SSH_IP_ADDRESS/g" | ${SSH_COMMAND} 'cat > bash_login'

  # create a remote user
  REMOTE_USER="user-${cluster_index}"
  ${SSH_COMMAND} -tt -- "
      set -x
      # create a remote user and set their password
      sudo userdel --remove --force ${REMOTE_USER}
      sudo groupdel ${REMOTE_USER}
      sudo groupadd --force --gid "$((2000 + $cluster_index))" ${REMOTE_USER}
      sudo useradd --uid "$((2000 + $cluster_index))" --gid "$((2000 + $cluster_index))" --create-home ${REMOTE_USER} --shell /bin/bash
      echo '${REMOTE_USER}:123456789' | sudo chpasswd

      # copy over kube config
      sudo rm -rf /home/${REMOTE_USER}/.kube
      sudo mv /home/${SSH_USER}/.kube /home/${REMOTE_USER}/

      # create the login message
      cat /home/${SSH_USER}/bash_login | sudo tee -a /home/${REMOTE_USER}/.bashrc > /dev/null

      # set file system permissions
      sudo chown -R ${REMOTE_USER}:${REMOTE_USER} /home/${REMOTE_USER}/.kube
      sudo chmod 640 /home/${REMOTE_USER}/.kube/config
  "

  info "Configuring remote k8s cluster with proper roles and helm"
  ${SSH_COMMAND} -tt "
    sudo su - '${REMOTE_USER}' -c 'kubectl create clusterrolebinding clusterRoleBinding --clusterrole=cluster-admin --serviceaccount=kube-system:default'
    sudo su - '${REMOTE_USER}' -c 'helm init --history-max 200'
    sudo su - '${REMOTE_USER}' -c 'kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta1/aio/deploy/recommended.yaml'
  "
done

info "For the instructor to ssh into the instance, execute the following command:"
info "    ${SSH_COMMAND}"

info "For the participants to ssh into the instance, execute the following command:"
info "    ssh user-\${N}@${SSH_IP_ADDRESS}"

# ] <-- needed because of Argbash
